{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Public access to Translation Model ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcfUjn9XePyl"
      },
      "source": [
        "**MIT License**\n",
        "\n",
        "Copyright (c) [2019] [Chinh Ngo]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdTrQ4WIRIE2"
      },
      "source": [
        "# Install dependencies.\n",
        "\n",
        "* `tensor2tensor`: a library with all necessary tools to perform training/inference of Transformers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPGni6fuvoTj",
        "outputId": "b69d34bd-7598-4cc1-838a-a63d6636fa7d"
      },
      "source": [
        "# Imports we need.\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Install Tensor2tensor\n",
        "!pip install -q -U tensor2tensor\n",
        "!pip install tensorflow-datasets==3.2.1\n",
        "\n",
        "print('All done.')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 21.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets==3.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/c9/d97bdf931edbae9aebc767633d088bd674136d5fe7587ef693b7cb6a1883/tensorflow_datasets-3.2.1-py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (2.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.19.5)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (20.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.27.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (4.41.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.12.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==3.2.1) (1.52.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==3.2.1) (53.0.0)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "Successfully installed tensorflow-datasets-3.2.1\n",
            "All done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udP-H4wlNdX4"
      },
      "source": [
        "# Setup some options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uza9j3ISNhls"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from os import path\n",
        "import collections\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "#@markdown 1. The problem is either `translate_vien_iwslt32k` or `translate_envi_iwslt32k`. This name will tell tensor2tensor how to properly set up training/testing data pipeline.\n",
        "\n",
        "problem = 'fb_wiki_and_book_m45_translate_envi_iwslt32k'  # @param\n",
        "\n",
        "#@markdown 2. We use the tiny setting of the transformer by default. This name will tell tensor2tensor to pick the corresponding Transformer architecture (default the small one).\n",
        "\n",
        "hparams_set = 'transformer_tall9'  # @param\n",
        "\n",
        "#@markdown 3. Next we specify the directory where all data involving this colab will be stored (training data, checkpoints, decoded text etc.)\n",
        "\n",
        "#@markdown * For GPU we use Google Drive Storage (free for everyone with a Google account, no need to install any payment method). This will create a directory in your Google Drive with the specified name.\n",
        "\n",
        "#@markdown * With TPU, unfortunately only Google Cloud Storage is usable (free trial with a payment method required). Here we specify a Storage bucket.\n",
        "\n",
        "google_cloud_bucket = 'ntkchinh_public'  # @param\n",
        "\n",
        "#@markdown Please note that only one of the two options above will be used depending on which runtime setting you are using.\n",
        "\n",
        "#@markdown 4. Now we specify all sub-directories:\n",
        "\n",
        "#@markdown * Data tfrecords (train/valid) is a special data format used by tensor2tensor for optimized reading/loading. They will be generated from raw texts files and stored into:\n",
        "data_dir = 'translation_envi'  # @param\n",
        "\n",
        "#@markdown * Training Machine Learning model generally takes a long time. We want to frequently save intermediate results (half-trained models or 'checkpoints') to:\n",
        "logdir = 'translation_envi'  # @param\n",
        "\n",
        "#@markdown * The temporary dir to store all the temp files during tfrecords data generation (e.g. downloads from the internet).\n",
        "\n",
        "tmp_dir = 'translation_envi'  # @param"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oILRLCWN_16u",
        "outputId": "4be9542b-f21c-48b7-a725-93dc404d0ac4"
      },
      "source": [
        "# Check if the runtime is set to TPU or GPU:\n",
        "use_tpu = True  # @param{type:\"boolean\"}\n",
        "# use_tpu = False\n",
        "\n",
        "  \n",
        "def setup_tpu():\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "  # Mount the bucket to colab, so that python package os can access to it.\n",
        "  # First we install gcsfuse to be able to mount Google Cloud Storage with Colab.\n",
        "  print('\\nInstalling gcsfuse')\n",
        "  !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "  !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "  !apt -qq update\n",
        "  !apt -qq install gcsfuse\n",
        "\n",
        "  bucket = google_cloud_bucket\n",
        "  print('Mounting bucket {} to local.'.format(bucket))\n",
        "  mount_point = '/content/{}'.format(bucket)\n",
        "  if not os.path.exists(mount_point):\n",
        "    tf.gfile.MakeDirs(mount_point)\n",
        "  \n",
        "  !fusermount -u $mount_point\n",
        "  !gcsfuse --implicit-dirs $bucket $mount_point\n",
        "  print('\\nMount point content:')\n",
        "  !ls $mount_point\n",
        "\n",
        "  # First we Connect to the TPU pod.\n",
        "  tpu_address = ''\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "    with tf.Session(tpu_address) as session:\n",
        "      devices = session.list_devices()\n",
        "      # Upload credentials to TPU.\n",
        "      with open('/content/adc.json', 'r') as f:\n",
        "        auth_info = json.load(f)\n",
        "      tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "\n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)\n",
        "\n",
        "  return mount_point, tpu_address\n",
        "\n",
        "\n",
        "if not use_tpu:\n",
        "  mount_point = setup_gpu()\n",
        "  tpu_address = ''\n",
        "else:\n",
        "  mount_point, tpu_address = setup_tpu()\n",
        "  \n",
        "print('\\nMount point: {}'.format(mount_point))\n",
        "print('TPU address: {}'.format(tpu_address))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Installing gcsfuse\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1974  100  1974    0     0  53351      0 --:--:-- --:--:-- --:--:-- 53351\n",
            "OK\n",
            "20 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.33.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Mounting bucket ntkchinh_public to local.\n",
            "Using mount point: /content/ntkchinh_public\n",
            "Opening GCS connection...\n",
            "Mounting file system...\n",
            "File system has been successfully mounted.\n",
            "\n",
            "Mount point content:\n",
            "translation_envi\n",
            "TPU address is grpc://10.25.25.42:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 7974801949009978256),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14799849929165045029),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2612460326722647743),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10359204068618933250),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6815685979948975574),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14492870576926074215),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1099885869293407318),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12743616719969177285),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1333967921359809663),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3550862902857655504),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 18121442460798631359)]\n",
            "\n",
            "Mount point: /content/ntkchinh_public\n",
            "TPU address: grpc://10.25.25.42:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHipozkT-VCZ"
      },
      "source": [
        "Now we create all the directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3dqhO8v-Uj3",
        "outputId": "3ee58025-a7f1-43f9-cff1-72a54931df1b"
      },
      "source": [
        "# Now we make all the paths absolute.\n",
        "logdir = os.path.join(mount_point, logdir)\n",
        "data_dir = os.path.join(mount_point, data_dir)\n",
        "tmp_dir = os.path.join(mount_point, tmp_dir)\n",
        "\n",
        "run_logdir = logdir\n",
        "\n",
        "print('log dir: {}'.format(run_logdir))\n",
        "print('data dir: {}'.format(data_dir))\n",
        "print('temp dir: {}'.format(tmp_dir))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log dir: /content/ntkchinh_public/translation_envi\n",
            "data dir: /content/ntkchinh_public/translation_envi\n",
            "temp dir: /content/ntkchinh_public/translation_envi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaDPi48oH3ug"
      },
      "source": [
        "# Clone or Pull source code from our Github repo `ntkchinh/some_new_repo`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsttrcZbH2t0",
        "outputId": "eac2082c-8d3f-4d9e-ee40-1a384b987543"
      },
      "source": [
        "src = '/content/translation_vien'\n",
        "if not os.path.exists(src):\n",
        "  os.chdir('/content')\n",
        "  ! git clone https://github.com/ntkchinh/translation_vien.git\n",
        "else:\n",
        "  % cd $src\n",
        "  ! git pull\n",
        "  % cd /\n",
        "\n",
        "print('\\n Source code:')\n",
        "%ls $src"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'translation_vien'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), done.\n",
            "\n",
            " Source code:\n",
            "problems.py  t2t_decoder.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFcKod5tRb9W",
        "outputId": "1c111566-5726-4871-a6fa-50d77a3a611a"
      },
      "source": [
        "!ls  $mount_point/translation_envi  #uhmok"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.ckpt.data-00000-of-00001\n",
            "model.ckpt.index\n",
            "model.ckpt.meta\n",
            "tst2013.en\n",
            "tst2013.vi\n",
            "vocab.fb_wiki_and_book_m45_translate_envi_iwslt32k.32768.subwords\n",
            "vocab.subwords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIAp4ctWufFS",
        "outputId": "fd18acbd-7743-44de-a971-72a91c5f7df5"
      },
      "source": [
        "decode_from_file = os.path.join(tmp_dir, 'tst2013.en')\n",
        "decode_to_file = 'tst2013.en2vi'  # no longer write to cloud bucket.\n",
        "ref_file = os.path.join(tmp_dir, 'tst2013.vi')\n",
        "\n",
        "if use_tpu:\n",
        "  # TPU wants the paths to begin with gs://\n",
        "  ckpt_dir = logdir.replace(mount_point, 'gs://{}'.format(google_cloud_bucket))\n",
        "ckpt_path = os.path.join(ckpt_dir, 'model.ckpt')\n",
        "\n",
        "print('Decode to file {}'.format(decode_to_file))\n",
        "!python $src/t2t_decoder.py \\\n",
        "--data_dir=$data_dir --problem=$problem \\\n",
        "--hparams_set=$hparams_set \\\n",
        "--model=transformer \\\n",
        "--decode_hparams=\"beam_size=4,alpha=0.6\"  \\\n",
        "--decode_from_file=$decode_from_file \\\n",
        "--decode_to_file=$decode_to_file  \\\n",
        "--checkpoint_path=$ckpt_path  \\\n",
        "--output_dir=$ckpt_dir  \\\n",
        "--use_tpu=$use_tpu \\\n",
        "--cloud_tpu_name=$tpu_address\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decode to file tst2013.en2vi\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/translation_vien/t2t_decoder.py:25: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/translation_vien/t2t_decoder.py:25: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/translation_vien/t2t_decoder.py:25: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/translation_vien/t2t_decoder.py:25: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/translation_vien/t2t_decoder.py:26: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/translation_vien/t2t_decoder.py:26: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f587ec16d08>) includes params argument, but params are not passed to Estimator.\n",
            "W0208 16:17:23.384145 140020228740992 estimator.py:1994] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f587ec16d08>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://ntkchinh_public/translation_envi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.25.25.42:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f587dbff2e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.25.25.42:8470', '_evaluation_master': 'grpc://10.25.25.42:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f5881095160>, 'use_tpu': True}\n",
            "I0208 16:17:23.385744 140020228740992 estimator.py:212] Using config: {'_model_dir': 'gs://ntkchinh_public/translation_envi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.25.25.42:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f587dbff2e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.25.25.42:8470', '_evaluation_master': 'grpc://10.25.25.42:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f5881095160>, 'use_tpu': True}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0208 16:17:23.386641 140020228740992 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
            "I0208 16:17:23.387315 140020228740992 decoding.py:407] decode_hp.batch_size not specified; default=32\n",
            "INFO:tensorflow:Performing decoding from file (/content/ntkchinh_public/translation_envi/tst2013.en).\n",
            "I0208 16:17:23.387442 140020228740992 decoding.py:418] Performing decoding from file (/content/ntkchinh_public/translation_envi/tst2013.en).\n",
            "INFO:tensorflow:Getting sorted inputs\n",
            "I0208 16:17:23.387534 140020228740992 decoding.py:863] Getting sorted inputs\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0208 16:17:23.553911 140020228740992 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.25.25.42:8470) for TPU system metadata.\n",
            "I0208 16:17:23.554814 140020228740992 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.25.25.42:8470) for TPU system metadata.\n",
            "2021-02-08 16:17:23.556137: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "I0208 16:17:23.568804 140020228740992 tpu_system_metadata.py:148] Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "I0208 16:17:23.569072 140020228740992 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "I0208 16:17:23.569161 140020228740992 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "I0208 16:17:23.569219 140020228740992 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7974801949009978256)\n",
            "I0208 16:17:23.569286 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7974801949009978256)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2612460326722647743)\n",
            "I0208 16:17:23.570076 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 2612460326722647743)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10359204068618933250)\n",
            "I0208 16:17:23.570145 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10359204068618933250)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6815685979948975574)\n",
            "I0208 16:17:23.570216 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6815685979948975574)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14492870576926074215)\n",
            "I0208 16:17:23.570272 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14492870576926074215)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1099885869293407318)\n",
            "I0208 16:17:23.570326 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1099885869293407318)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12743616719969177285)\n",
            "I0208 16:17:23.570378 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12743616719969177285)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1333967921359809663)\n",
            "I0208 16:17:23.570430 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1333967921359809663)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3550862902857655504)\n",
            "I0208 16:17:23.570482 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3550862902857655504)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 18121442460798631359)\n",
            "I0208 16:17:23.570533 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 18121442460798631359)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14799849929165045029)\n",
            "I0208 16:17:23.570602 140020228740992 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14799849929165045029)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0208 16:17:23.571982 140020228740992 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function decode_from_file.<locals>.input_fn.<locals>.<lambda> at 0x7f587dbc2400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0208 16:17:23.607488 140020228740992 ag_logging.py:146] Entity <function decode_from_file.<locals>.input_fn.<locals>.<lambda> at 0x7f587dbc2400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function _InputsWithStoppingSignals.insert_stopping_signal.<locals>._map_fn at 0x7f587dbc2b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0208 16:17:23.638987 140020228740992 ag_logging.py:146] Entity <function _InputsWithStoppingSignals.insert_stopping_signal.<locals>._map_fn at 0x7f587dbc2b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function _InputsWithStoppingSignals.insert_stopping_signal.<locals>._map_fn at 0x7f587dbc2ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0208 16:17:23.679339 140020228740992 ag_logging.py:146] Entity <function _InputsWithStoppingSignals.insert_stopping_signal.<locals>._map_fn at 0x7f587dbc2ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "2021-02-08 16:17:23.778961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-02-08 16:17:23.791461: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-02-08 16:17:23.791567: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c48c811f5b64): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
            "I0208 16:17:23.808469 140020228740992 t2t_model.py:2267] Setting T2TModel mode to 'infer'\n",
            "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
            "I0208 16:17:23.809135 140020228740992 t2t_model.py:2267] Setting hparams.dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
            "I0208 16:17:23.809284 140020228740992 t2t_model.py:2267] Setting hparams.label_smoothing to 0.0\n",
            "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "I0208 16:17:23.809406 140020228740992 t2t_model.py:2267] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
            "I0208 16:17:23.809497 140020228740992 t2t_model.py:2267] Setting hparams.symbol_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
            "I0208 16:17:23.809609 140020228740992 t2t_model.py:2267] Setting hparams.attention_dropout to 0.0\n",
            "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
            "I0208 16:17:23.809790 140020228740992 t2t_model.py:2267] Setting hparams.relu_dropout to 0.0\n",
            "INFO:tensorflow:Beam Decoding with beam size 4\n",
            "I0208 16:17:23.812218 140020228740992 t2t_model.py:2267] Beam Decoding with beam size 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_attention.py:931: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0208 16:17:24.016775 140020228740992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_attention.py:931: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0208 16:17:24.095785 140020228740992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_attention.py:4688: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.\n",
            "W0208 16:17:27.723233 140020228740992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_attention.py:4688: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0208 16:17:31.265745 140020228740992 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0208 16:17:31.468468 140020228740992 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0208 16:17:33.352031 140020228740992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0208 16:17:33.356958 140020228740992 tpu_estimator.py:506] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0208 16:17:34.086478 140020228740992 monitored_session.py:240] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://ntkchinh_public/translation_envi/model.ckpt\n",
            "I0208 16:17:34.128604 140020228740992 saver.py:1284] Restoring parameters from gs://ntkchinh_public/translation_envi/model.ckpt\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0208 16:17:36.832473 140020228740992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0208 16:17:37.150296 140020228740992 session_manager.py:502] Done running local_init_op.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:818: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0208 16:17:37.596029 140020228740992 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:818: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Init TPU system\n",
            "I0208 16:17:37.920737 140020228740992 tpu_estimator.py:567] Init TPU system\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imHOiie6XSli",
        "outputId": "027fb424-aee9-450f-de32-55ad11e11941"
      },
      "source": [
        "!pwd\n",
        "!ls\n",
        "!head -10 $decode_to_file"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "bin\t dev   lib32  opt   sbin   tensorflow-1.15.2  usr\n",
            "boot\t etc   lib64  proc  srv    tmp\t\t      var\n",
            "content  home  media  root  swift  tools\n",
            "datalab  lib   mnt    run   sys    tst2013.en2vi\n",
            "Khi còn nhỏ , tôi nghĩ đất nước mình là tốt nhất trên hành tinh này , và tôi lớn lên hát một bài hát tên là &quot; Không có gì để ghen tị . &quot;\n",
            "Và tôi đã rất tự hào .\n",
            "Ở trường , chúng tôi dành rất nhiều thời gian nghiên cứu lịch sử của Kim Il-Sung , nhưng chúng tôi chưa bao giờ biết nhiều về thế giới bên ngoài , ngoại trừ Mỹ , Hàn Quốc , Nhật Bản là kẻ thù .\n",
            "Mặc dù tôi thường băn khoăn về thế giới bên ngoài , tôi nghĩ rằng mình sẽ dành cả cuộc đời mình ở Bắc Triều Tiên , cho đến khi mọi thứ đột nhiên thay đổi .\n",
            "Khi tôi 7 tuổi , tôi chứng kiến lần hành quyết trước công chúng đầu tiên , nhưng tôi nghĩ cuộc sống của tôi ở Bắc Triều Tiên là bình thường .\n",
            "Gia đình tôi không nghèo , và bản thân tôi , tôi chưa bao giờ trải qua cơn đói .\n",
            "Nhưng một ngày , vào năm 1995 , mẹ tôi mang về nhà một lá thư từ chị của đồng nghiệp\n",
            "Nó viết , &quot; Khi bạn đọc cái này , cả năm thành viên trong gia đình sẽ không tồn tại trên thế giới này , bởi vì chúng tôi đã không ăn trong hai tuần qua .\n",
            "Chúng ta cùng nằm trên sàn nhà , và cơ thể của chúng ta quá yếu nên chúng ta sẵn sàng chết . &quot;\n",
            "Tôi đã rất sốc .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xY0pt2Dwncf",
        "outputId": "83a03bc6-24e8-49b8-a17c-b7841db17cdf"
      },
      "source": [
        "print('\\nCompare {} with reference {}'.format(decode_to_file, ref_file))\n",
        "!t2t-bleu --translation=$decode_to_file --reference=$ref_file"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Compare tst2013.en2vi with reference /content/ntkchinh_public/translation_envi/tst2013.vi\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/bin/t2t-bleu:17: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/bin/t2t-bleu:17: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/bin/t2t-bleu:18: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "BLEU_uncased =  37.49\n",
            "BLEU_cased =  36.63\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}